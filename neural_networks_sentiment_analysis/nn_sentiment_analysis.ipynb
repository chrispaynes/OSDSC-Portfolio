{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75dc29a7-d9cd-452f-bb0d-08a3bb57db94",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a459e4d-fffa-4dda-a56b-66c889ffb3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: keras<2.11,>=2.10.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.0.7)\n",
      "Requirement already satisfied: packaging in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.19.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.11.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: keras in /Users/chris/opt/anaconda3/lib/python3.9/site-packages (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "! python3.9 -m pip install tensorflow\n",
    "! python3.9 -m pip install keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69534511-9d11-4389-8816-af4520cd5f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4080ef-7bb5-45b3-b8de-e5b2a0480f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# suppress scientific notation in Pandas\n",
    "pd.options.display.float_format = \"{:.2f}\".format\n",
    "pd.set_option(\"display.max_colwidth\", 5000)\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"precision\", 3)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 10]\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "\n",
    "sns.set()\n",
    "sns.set_context(\"notebook\", rc={\"lines.linewidth\": 2.5})\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df44029-4043-4212-aa5a-4dcbdbd37834",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_json(\"./src/amazon/reviews_Digital_Music_5.json\", lines=True)\n",
    "# df = original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c38927-ba81-407e-ba22-12c35bf29cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data set as a data frame.\n",
    "# Load packages for TensorFlow, Keras, and other libraries.\n",
    "# EDA – to better understand the data structure.\n",
    "# Remove unusual characters: uppercase letters, punctuation marks, emoticons, and non-English characters.\n",
    "# Measure the vocabulary size using (bags of words, etc.).\n",
    "# Explore N-Gram (unigram, bigram, and trigram) structures for usefulness in text analysis as applicable.\n",
    "# Determine the word embedding and explore embedded words based on target inputs.\n",
    "# Set the maximum sequence length based on the length of the longest sentence in the data set.\n",
    "# Tokenize sentences into a list of tokens and remove stop words.\n",
    "# Pad cleaned sentences to fit the maximum sequence length after each text sequence.\n",
    "# Create an activation function filled with dense layers of the neural network.\n",
    "# Split the data set into training and test sets or into training/test/validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a58bedb0-46b4-434c-81d9-6df7b2259fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A3EBHHCZO6V2A4</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>Amaranth \"music fan\"</td>\n",
       "      <td>[3, 3]</td>\n",
       "      <td>It's hard to believe \"Memory of Trees\" came out 11 years ago;it has held up well over the passage of time.It's Enya's last great album before the New Age/pop of \"Amarantine\" and \"Day without rain.\" Back in 1995,Enya still had her creative spark,her own voice.I agree with the reviewer who said that this is her saddest album;it is melancholy,bittersweet,from the opening title song.\"Memory of Trees\" is elegaic&amp;majestic.;\"Pax Deorum\" sounds like it is from a Requiem Mass,it is a dark threnody.Unlike the reviewer who said that this has a \"disconcerting\" blend of spirituality&amp;sensuality;,I don't find it disconcerting at all.\"Anywhere is\" is a hopeful song,looking to possibilities.\"Hope has a place\" is about love,but it is up to the listener to decide if it is romantic,platonic,etc.I've always had a soft spot for this song.\"On my way home\" is a triumphant ending about return.This is truly a masterpiece of New Age music,a must for any Enya fan!</td>\n",
       "      <td>5</td>\n",
       "      <td>Enya's last great album</td>\n",
       "      <td>1158019200</td>\n",
       "      <td>09 12, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AZPWAXJG9OJXV</td>\n",
       "      <td>5555991584</td>\n",
       "      <td>bethtexas</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>A clasically-styled and introverted album, Memory of Trees is a masterpiece of subtlety.  Many of the songs have an endearing shyness to them - soft piano and a lovely, quiet voice.  But within every introvert is an inferno, and Enya lets that fire explode on a couple of songs that absolutely burst with an expected raw power.If you've never heard Enya before, you might want to start with one of her more popularized works, like Watermark, just to play it safe.  But if you're already a fan, then your collection is not complete without this beautiful work of musical art.</td>\n",
       "      <td>5</td>\n",
       "      <td>Enya at her most elegant</td>\n",
       "      <td>991526400</td>\n",
       "      <td>06 3, 2001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin          reviewerName helpful  \\\n",
       "0  A3EBHHCZO6V2A4  5555991584  Amaranth \"music fan\"  [3, 3]   \n",
       "1   AZPWAXJG9OJXV  5555991584             bethtexas  [0, 0]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               reviewText  \\\n",
       "0  It's hard to believe \"Memory of Trees\" came out 11 years ago;it has held up well over the passage of time.It's Enya's last great album before the New Age/pop of \"Amarantine\" and \"Day without rain.\" Back in 1995,Enya still had her creative spark,her own voice.I agree with the reviewer who said that this is her saddest album;it is melancholy,bittersweet,from the opening title song.\"Memory of Trees\" is elegaic&majestic.;\"Pax Deorum\" sounds like it is from a Requiem Mass,it is a dark threnody.Unlike the reviewer who said that this has a \"disconcerting\" blend of spirituality&sensuality;,I don't find it disconcerting at all.\"Anywhere is\" is a hopeful song,looking to possibilities.\"Hope has a place\" is about love,but it is up to the listener to decide if it is romantic,platonic,etc.I've always had a soft spot for this song.\"On my way home\" is a triumphant ending about return.This is truly a masterpiece of New Age music,a must for any Enya fan!   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                          A clasically-styled and introverted album, Memory of Trees is a masterpiece of subtlety.  Many of the songs have an endearing shyness to them - soft piano and a lovely, quiet voice.  But within every introvert is an inferno, and Enya lets that fire explode on a couple of songs that absolutely burst with an expected raw power.If you've never heard Enya before, you might want to start with one of her more popularized works, like Watermark, just to play it safe.  But if you're already a fan, then your collection is not complete without this beautiful work of musical art.   \n",
       "\n",
       "   overall                   summary  unixReviewTime   reviewTime  \n",
       "0        5   Enya's last great album      1158019200  09 12, 2006  \n",
       "1        5  Enya at her most elegant       991526400   06 3, 2001  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 64706 entries, 0 to 64705\n",
      "Data columns (total 9 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   reviewerID      64706 non-null  object\n",
      " 1   asin            64706 non-null  object\n",
      " 2   reviewerName    64529 non-null  object\n",
      " 3   helpful         64706 non-null  object\n",
      " 4   reviewText      64706 non-null  object\n",
      " 5   overall         64706 non-null  int64 \n",
      " 6   summary         64706 non-null  object\n",
      " 7   unixReviewTime  64706 non-null  int64 \n",
      " 8   reviewTime      64706 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 4.4+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(64706, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.\tAnalyzing the data and review length.\n",
    "\n",
    "original_df.head(2)\n",
    "original_df.info()\n",
    "original_df.shape\n",
    "\n",
    "# 2.\tCreating a dictionary and applying it to remove extraneous characters.\n",
    "# 3.\tDeciding on a typical review length.\n",
    "# 4.\tTokenization.\n",
    "# 5.\tApplying Tensorflow’s keras and layers methods\n",
    "# 6.\tSplitting the dataset into train and test\n",
    "# 7.\tFitting the model\n",
    "# 8.\tModel evaluation and reporting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610a0ff8-95c6-49d0-8752-2981bef9bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Task Two: Actually, it is pretty simple.  There are three text files, Amazon, IMDB, and Yelp.  You want to do a neural net to find the Sentiment index among the reviews.  These are the high-level ten basic steps:\n",
    "\n",
    "# 1.\tIf you run a couple of FOR loops to translate characters (essentially “cleaning up”).   There will be 52 unique characters remaining.\n",
    "# 2.\tPlot a histogram to find the length of the reviews. Most of the 500 reviews will be under 150 characters in length.\n",
    "# 3.\tCreate a dictionary for characters and tokens.\n",
    "# 4.\tUse arrays to hold each review and assign to it a list of one-hot-encoded characters.\n",
    "# 5.\tCode the output array to represent the review as positive (1) or negative (0).  The target value is binary.\n",
    "# 6.\tAdd terminators to the end of the data to fill the fixed length strings.\n",
    "# 7.\tUsing sklearn, numpy, and keras train a neural net.  Split data prior to training into test and validation.\n",
    "# 8.\tBy reading through the data in the network, weights are adjusted until errors are minimized.  Each period or cycle is referred to as an epoch.\n",
    "# 9.\tThen, you run a sequential neural net using keras.Sequential()\n",
    "# 10.\tAfter using the training process iteratively, the model.evaluate(x, y) will confirm the reliability. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd6d3f2-efc3-4498-8cad-5d0abb32237a",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "You have seen the power of using data analytical techniques to help organizations make data-driven decisions and now want to extend these models into areas of machine learning and artificial intelligence. In this task, you will explore the use of neural networks and natural language processing (NLP).\n",
    "\n",
    "In this task, you will choose a data file from the Web Links section. The available data sets are as follows:\n",
    "- [Amazon Product Data set](http://jmcauley.ucsd.edu/data/amazon/)\n",
    "- [UCSD Recommender Systems Data sets](https://cseweb.ucsd.edu/~jmcauley/datasets.html)\n",
    "- UCI Sentiment Labeled Sentences Data set\n",
    "\n",
    "For this task, you will build a neural network designed to learn word usage and context using NLP techniques. You will provide visualizations and a report, as well as build your network in an interactive development environment.\n",
    "\n",
    "In the telecom munications industry, customers can choose from multiple service providers and actively switch from one provider to another. Customer churn is defined as the percentage of customers who stopped using a provider’s product or service during a certain time frame. In this highly competitive market, some telecommunications industries can experience average annual churn rates as high as 25 Given that it costs 10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many providers retaining highly profitable customers is the number one business goal. To reduce customer churn, telecom munications companies need to predict which customers are at high risk of churn.\n",
    "\n",
    "As part of the “churn” project, executives would like to see consider a time series on revenue from the first years of operation. Once they understand any patterns in that data, they feel confident in understanding the impact of churn in current times. The given time series data records the daily revenue, in million dollars, during the first two years of operation.\n",
    "\n",
    "**Data File being used:**\n",
    "teleco_time_series.csv\n",
    "\n",
    "**Data Dictionary:**\n",
    "- The data set consists of 731 rows and two columns:\n",
    "    - Day Day during first two years of operation\n",
    "    - Revenue Revenue in million dollars\n",
    "    \n",
    "Review the data dictionary and considerations related to the raw data file you have chosen and prepare the data for time series modeling. You will then analyze that data set using time series modeling, create visualizations, generate forecasts, and deliver the results of your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9841393-d7d9-4ae2-b604-80af93c1a091",
   "metadata": {},
   "source": [
    "# Part 0: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf34752-167d-4c21-b0b6-37a4bad4d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3feed-01e1-45b2-9504-6dce3d32a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbc80cb-6c1a-4c4d-ac76-34da4494fe10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d39046-995c-4065-bb60-ea190db9e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.isnull().sum(), columns=[\"# NaNs\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98c8ce-c3df-400a-b8c1-575939e3bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{df.isnull().sum().sum():,} Total NaN Cells\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d145f-87a1-4c68-a267-94d7a096017b",
   "metadata": {},
   "source": [
    "# Part I:  Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b9d7f-6923-4a2a-b459-7b4e37631564",
   "metadata": {},
   "source": [
    "## A.  Describe the purpose of this data analysis by doing the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1dbff-4f9d-4ef9-988f-4d7e71c1f01d",
   "metadata": {},
   "source": [
    "### 1.  Summarize one research question that you will answer using neural network models and NLP techniques. Be sure the research question is relevant to a real-world organizational situation and sentiment analysis captured in your chosen dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1d9260-01ed-4024-84dc-da128aa1f924",
   "metadata": {},
   "source": [
    "### 2.  Define the objectives or goals of the data analysis. Be sure the objectives or goals are reasonable within the scope of the research question and are represented in the available data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061f1418-c2f2-46b5-958d-84e8ec214f09",
   "metadata": {},
   "source": [
    "### 3.  Identify a type of neural network capable of performing a text classification task that can be trained to produce useful predictions on text sequences on the selected data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f14718-7f23-44a3-b40d-809f3fd0980f",
   "metadata": {},
   "source": [
    "# Part II:  Data Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eceba8-6baa-49f8-9aa4-2726ae8ca5fc",
   "metadata": {},
   "source": [
    "## B.  Summarize the data cleaning process by doing the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78df2325-4525-4669-b0f7-900749b75479",
   "metadata": {},
   "source": [
    "### 1.  Perform exploratory data analysis on the chosen dataset, and include an explanation of each of the following elements:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6d5d4-3345-46df-968c-191a6beb8850",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e821fcc0-da0d-4249-a352-26704087690c",
   "metadata": {},
   "source": [
    "#### presence of unusual characters (e.g., emojis, non-English characters, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d410971c-e178-437c-b304-f5ce515b7cf8",
   "metadata": {},
   "source": [
    "#### vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbfbe24-d0d1-4b21-9093-aededebf11d5",
   "metadata": {},
   "source": [
    "#### proposed word embedding length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0032a5-70a5-4ec4-878a-40ddac51b8dc",
   "metadata": {},
   "source": [
    "#### statistical justification for the chosen maximum sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6e817-eaaa-46fd-839c-b1a0cb00563d",
   "metadata": {},
   "source": [
    "### 2.  Describe the goals of the tokenization process, including any code generated and packages that are used to normalize text during the tokenization process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbd1686-20f5-486d-82eb-36900ba0f7e3",
   "metadata": {},
   "source": [
    "### 3.  Explain the padding process used to standardize the length of sequences, including the following in your explanation:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c08a48-a990-4daa-b857-5a7a76f1109a",
   "metadata": {},
   "source": [
    "#### if the padding occurs before or after the text sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b91fcce-d35c-4674-926c-c7b949b595c3",
   "metadata": {},
   "source": [
    "#### a screenshot of a single padded sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764cff8-c762-4e92-849d-207add8190c7",
   "metadata": {},
   "source": [
    "### 4.  Identify how many categories of sentiment will be used and an activation function for the final dense layer of the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efaf3fa2-ce68-4c02-b2db-d41483b2e3b1",
   "metadata": {},
   "source": [
    "### 5.  Explain the steps used to prepare the data for analysis, including the size of the training, validation, and test set split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84a30d-eeea-4f77-80d9-6903dec764fe",
   "metadata": {},
   "source": [
    "### 6.  Provide a copy of the prepared dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4c8a61-5107-474b-a2ff-fdb3146e74dd",
   "metadata": {},
   "source": [
    "# Part III:  Network Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7275f-87b2-45f8-8dc6-0c6424738d68",
   "metadata": {},
   "source": [
    "## C.  Describe the type of network used by doing the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ad2066-8609-4e20-8eaa-faaf77bd97ac",
   "metadata": {},
   "source": [
    "### 1.  Provide the output of the model summary of the function from TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb545e-9ece-4e87-8b2b-fb49e6cff79e",
   "metadata": {},
   "source": [
    "### 2.  Discuss the number of layers, the type of layers, and total number of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d82b75-2ede-4601-a01e-6b23a405eeea",
   "metadata": {},
   "source": [
    "\n",
    "### 3.  Justify the choice of hyperparameters, including the following elements:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff93744-c21b-4d6d-9a89-bbbc84ed1379",
   "metadata": {},
   "source": [
    "\n",
    "#### activation functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea11cd2-d89a-4757-8d26-02d73139d054",
   "metadata": {},
   "source": [
    "#### number of nodes per layer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74640e60-786c-4b46-9304-84fbecc2811e",
   "metadata": {},
   "source": [
    "#### loss function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70d71a-5b6f-422f-ba46-b56e1d20f217",
   "metadata": {},
   "source": [
    "\n",
    "#### optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98448e48-3c69-4664-9905-437dc99eac7e",
   "metadata": {},
   "source": [
    "#### stopping criteria\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec97f1-3fb5-4118-a08e-95ac6a0855db",
   "metadata": {},
   "source": [
    "#### evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b70d2-09bb-4dcc-8290-f5b7d649384d",
   "metadata": {},
   "source": [
    "# Part IV:  Model Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963a4800-d697-46f7-89d6-25fccd086822",
   "metadata": {},
   "source": [
    "## D.  Evaluate the model training process and its relevant outcomes by doing the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f87644-36be-46c2-a40f-892049b72461",
   "metadata": {},
   "source": [
    "### 1.  Discuss the impact of using stopping criteria instead of defining the number of epochs, including a screenshot showing the final training epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f6bc8b-d8b4-45a8-a9fd-c791e8853e3c",
   "metadata": {},
   "source": [
    "### 2.  Provide visualizations of the model’s training process, including a line graph of the loss and chosen evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd88d621-7db6-4184-9be3-330c5cab8be4",
   "metadata": {},
   "source": [
    "\n",
    "### 3.  Assess the fitness of the model and any measures taken to address overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23196a32-dae8-4471-b43c-62b4925d231b",
   "metadata": {},
   "source": [
    "\n",
    "### 4.  Discuss the predictive accuracy of the trained network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6203819-6583-4e6a-afa7-fa6d8f147500",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cff371e6-09e5-42fd-ba25-a2c93e6a3c87",
   "metadata": {},
   "source": [
    "# Part V:  Summary and Recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcc2f22-708c-4ab1-b17f-61750b0d0149",
   "metadata": {},
   "source": [
    "## E.  Provide the code used to save the trained network within the neural network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a978c7-f933-42ef-857b-a7fbb746fd50",
   "metadata": {},
   "source": [
    "## F.  Discuss the functionality of your neural network, including the impact of the network architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc5b3c8-6036-4f7f-8e80-e8fe6021bd42",
   "metadata": {},
   "source": [
    "## G.  Recommend a course of action based on your results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183c122-5747-4c36-9950-9fb865359a45",
   "metadata": {},
   "source": [
    "# Part VI: Reporting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692d5f95-73c6-451a-9005-a1f019d0779a",
   "metadata": {},
   "source": [
    "## H.  Create your neural network using an industry-relevant interactive development environment (e.g., a Jupyter Notebook). Include a PDF or HTML document of your executed notebook presentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dc577b-b770-40e2-bd67-62b200704e0f",
   "metadata": {},
   "source": [
    "## I.  List the web sources used to acquire data or segments of third-party code to support the application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c181023-2ad6-4bbf-a637-c2f18a54bf99",
   "metadata": {},
   "source": [
    "## J.  Acknowledge sources, using in-text citations and references, for content that is quoted, paraphrased, or summarized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a7aa00-40d4-4cf2-a983-3d7c303d5b01",
   "metadata": {},
   "source": [
    "## K.  Demonstrate professional communication in the content and presentation of your submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f48d2bc-ae9d-4f75-b7c1-0dcf0f0a7796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
