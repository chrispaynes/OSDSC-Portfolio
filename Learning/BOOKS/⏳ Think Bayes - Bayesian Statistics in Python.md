- https://allendowney.github.io/ThinkBayes2/


# 01. Probability
The foundation of Bayesian statistics is Bayes’s Theorem, and the foundation of Bayes’s Theorem is conditional probability.

A probability is a fraction of a finite set. For example, if we survey 1000 people, and 20 of them are bank tellers, the fraction that work as bank tellers is 0.02 or 2%. If we choose a person from this population at random, the probability that they are a bank teller is 2%.

1.7. Conditional Probability

Conditional probability is a probability that depends on a condition, but that might not be the most helpful definition. Here are some examples:

    What is the probability that a respondent is a Democrat, given that they are liberal?

    What is the probability that a respondent is female, given that they are a banker?

    What is the probability that a respondent is liberal, given that they are female?


# 02. Bayes’s Theorem

# 03. Distributions

# 04. Estimating Proportions

# 05. Estimating Counts

# 06. Odds and Addends

# 07. Minimum, Maximum, and Mixture

# 08. Poisson Processes

# 09. Decision Analysis

# 10. Testing

# 11. Comparison

# 12. Classification

# 13. Inference

# 14. Survival Analysis

# 15. Mark and Recapture

# 16. Logistic Regression

# 17. Regression

# 18. Conjugate Priors

# 19. MCMC

# 20. Approximate Bayesian Computation
