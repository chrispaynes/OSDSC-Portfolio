## 1 - Packets of thought (NLP overview)
> Once you extract structured numerical data, vectors, from natural language, you can take advantage of all the tools of mathematics and machine learning. These breakthrough ideas opened up a world of “semantic” analysis, allowing computers to interpret and store the “meaning” of statements rather than just word or character counts. Semantic analysis, along with statistics, can help resolve the ambiguity of natural language—the fact that words or phrases often have multiple meanings or interpretations.

> This theory of mind about the human processor of language turns out to be a powerful assumption. It allows us to say a lot with few words if we assume that the “processor” has access to a lifetime of common sense knowledge about the world. This degree of compression is still out of reach for machines. There is no clear “theory of mind” you can point to in an NLP pipeline. However, we show you techniques in later chapters to help machines build ontologies, or knowledge bases, of common sense knowledge to help interpret statements that rely on this knowledge.

> A search engine can provide more meaningful results if it indexes web pages or document archives in a way that takes into account the meaning of natural language text. Autocomplete uses NLP to complete your thought and is common among search engines and mobile phone keyboards. Many word processors, browser plugins, and text editors have spelling correctors, grammar checkers, concordance composers, and most recently, style coaches. Some dialog engines (chatbots) use natural language search to find a response to their conversation partner’s message.

> When you type “Good Morn’n Rosa,” a computer sees only “01000111 01101111 01101111 ...”. How can you program a chatbot to respond to this binary stream intelligently? Could a nested tree of conditionals (if... else... statements) check each one of those bits and act on them individually? This would be equivalent to writing a special kind of program called a finite state machine (FSM). An FSM that outputs a sequence of new symbols as it runs, like the Python str.translate function, is called a finite state transducer (FST).

> A machine that processes this kind of language can be thought of as a formal mathematical object called a finite state machine or deterministic finite automaton (DFA).
## 2 - Build your vocabulary (word tokenization)

## 3 - Math with words (TF-IDF vectors)

## 4 - Finding meaning in word counts (semantic analysis)

## 5 - Baby steps with neural networks (perceptrons and backpropagation)

## 6 - Reasoning with word vectors (Word2vec)

## 7 - Getting words in order with convolutional neural networks (CNNs)

## 8 - Loopy (recurrent) neural networks (RNNs)

## 9 - Improving retention with long short-term memory networks

## 10 - Sequence-to-sequence models and attention

## 11 - Information extraction (named entity extraction and question answering)

## 12 - Getting chatty (dialog engines)

## 13 - Scaling up (optimization, parallelization, and batch processing)

## A -. Your NLP tools

## B -. Playful Python and regular expressions

## C -. Vectors and matrices (linear algebra fundamentals)

## D -. Machine learning tools and techniques

## E -. Setting up your AWS GPU

## F -. Locality sensitive hashing

## 2 - Build your vocabulary (word tokenization)

## 3 - Math with words (TF-IDF vectors)

## 4 - Finding meaning in word counts (semantic analysis)

## 5 - Baby steps with neural networks (perceptrons and backpropagation)

## 6 - Reasoning with word vectors (Word2vec)

## 7 - Getting words in order with convolutional neural networks (CNNs)

## 8 - Loopy (recurrent) neural networks (RNNs)

## 9 - Improving retention with long short-term memory networks

## 10 - Sequence-to-sequence models and attention

## 11 - Information extraction (named entity extraction and question answering)

## 12 - Getting chatty (dialog engines)

## 13 - Scaling up (optimization, parallelization, and batch processing)

---
## A - Your NLP tools

## B - Playful Python and regular expressions

## C - Vectors and matrices (linear algebra fundamentals)

## D - Machine learning tools and techniques

## E - Setting up your AWS GPU

## F - Locality sensitive hashing